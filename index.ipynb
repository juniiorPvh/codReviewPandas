{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Remove caracteres especiais e normaliza espaços\"\"\"\n",
    "    text = re.sub(r'[\\*\\#]', '', text)  # Remove negrito e marcadores\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Regex melhorado para cargos (inclui TÉCNICO e variações)\n",
    "position_pattern = re.compile(\n",
    "    r'(TÉCNICO)\\s*[-\\s]\\s*([^\\-\\n]+?)\\s*$',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Regex para local\n",
    "location_pattern = re.compile(\n",
    "    r'(TRIBUNAL DE JUSTIÇA|COMARCAS DO ESTADO).*?(\\([A-Z]{2}\\))?$'\n",
    ")\n",
    "\n",
    "# Regex para candidatos (mais flexível)\n",
    "candidate_pattern_ob = re.compile(\n",
    "    r'^(\\d+[/-]?\\d*[/-]?\\d+)\\s+([^\\d]+?)\\s+(\\d+[,.]\\d+|\\d+)\\s+(\\d+[,.]\\d+|\\d+)\\s+'\n",
    "    r'(\\d+[,.]\\d+|\\d+)\\s+(\\d+[,.]\\d+|\\d+)\\s+(\\d+[,.]\\d+|\\d+)\\s+(.+)$'\n",
    ")\n",
    "candidate_pattern_dis = re.compile(\n",
    "     r'^(\\d+)\\s+([^\\d]+?)\\s+(\\d+[,.]\\d+)\\s+(.+)$'\n",
    ")\n",
    "\n",
    "data_obje = []\n",
    "data_disc = []\n",
    "current_position = None\n",
    "current_location = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(\"prova_objetiva.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        for line in text.split('\\n'):\n",
    "            line = clean_text(line)\n",
    "            \n",
    "            # Pular linhas irrelevantes\n",
    "            if any(term.lower() in line.lower() for term in [\n",
    "                \"instituto\", \"página\", \"resultado\", \"edital\", \"concurso\"\n",
    "            ]) and not any(term in line for term in [\"TRIBUNAL\", \"COMARCAS\"]):\n",
    "                continue\n",
    "                \n",
    "            # Verificar cargo (ANALISTA ou TÉCNICO)\n",
    "            position_match = position_pattern.search(line)\n",
    "            if position_match:\n",
    "                tipo = position_match.group(1).upper()\n",
    "                especialidade = position_match.group(2).strip()\n",
    "                current_position = f\"{tipo} - {especialidade}\"\n",
    "                # print(f\"Cargo detectado: {current_position}\")  # Debug\n",
    "                continue\n",
    "                \n",
    "            # Verificar localização\n",
    "            location_match = location_pattern.search(line)\n",
    "            if location_match:\n",
    "                current_location = line.strip()\n",
    "                # print(f\"Local detectado: {current_location}\")  # Debug\n",
    "                continue\n",
    "                \n",
    "            # Verificar candidato\n",
    "            candidate_match = candidate_pattern_ob.match(line)\n",
    "            if candidate_match and current_position and current_location:\n",
    "                inscricao = candidate_match.group(1)\n",
    "                nome = candidate_match.group(2).strip()\n",
    "                \n",
    "                # Adicionar à lista de dados\n",
    "                data_obje.append([\n",
    "                    inscricao,\n",
    "                    nome,\n",
    "                    float(candidate_match.group(3).replace(',', '.')),\n",
    "                    float(candidate_match.group(4).replace(',', '.')),\n",
    "                    float(candidate_match.group(5).replace(',', '.')),\n",
    "                    float(candidate_match.group(6).replace(',', '.')),\n",
    "                    float(candidate_match.group(7).replace(',', '.')),\n",
    "                    candidate_match.group(8),\n",
    "                    current_position,\n",
    "                    current_location\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar DataFrame\n",
    "columns_ob = [\n",
    "    \"Inscrição\", \"Nome\", \"Língua Portuguesa\", \n",
    "    \"Conhecimentos Transversais\", \"História e Geografia\",\n",
    "    \"Conhecimentos Específicos\", \"Nota Objetiva\", \n",
    "    \"Situação\", \"Cargo\", \"Local\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data_obje, columns=columns_ob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(\"prova_discursiva.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        for line in text.split('\\n'):\n",
    "            line = clean_text(line)\n",
    "            # Pular linhas irrelevantes\n",
    "            if any(term.lower() in line.lower() for term in [\n",
    "                \"instituto\", \"página\", \"resultado\", \"edital\", \"concurso\", \"candidatos\", \"Consulplan\"\n",
    "            ]) and not any(term in line for term in [\"TRIBUNAL\", \"COMARCAS\"]):\n",
    "                continue\n",
    "\n",
    "                \n",
    "            # Verificar cargo (ANALISTA ou TÉCNICO)\n",
    "            position_match = position_pattern.search(line)\n",
    "            if position_match:\n",
    "                tipo = position_match.group(1).upper()\n",
    "                especialidade = position_match.group(2).strip()\n",
    "                current_position = f\"{tipo} - {especialidade}\"\n",
    "                # print(f\"Cargo detectado: {current_position}\")  # Debug\n",
    "                continue\n",
    "                \n",
    "            # Verificar localização\n",
    "            location_match = location_pattern.search(line)\n",
    "            if location_match:\n",
    "                current_location = line.strip()\n",
    "                # print(f\"Local detectado: {current_location}\")  # Debug\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            # Verificar candidato\n",
    "            candidate_match = candidate_pattern_dis.match(line)\n",
    "            if candidate_match and current_position and current_location:\n",
    "                inscricao = candidate_match.group(1)\n",
    "                nome = candidate_match.group(2).strip()\n",
    "                \n",
    "                # Adicionar à lista de dados\n",
    "                data_disc.append([\n",
    "                    inscricao,\n",
    "                    nome,\n",
    "                    float(candidate_match.group(3).replace(',', '.')),\n",
    "                    candidate_match.group(4),\n",
    "                    current_position,\n",
    "                    current_location\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame\n",
    "columns_dis = [\n",
    "    \"Inscrição\", \"Nome\", \"Prova Discursiva\", \n",
    "    \"Situação\", \"Cargo\", \"Local\"\n",
    "]\n",
    "\n",
    "df2 = pd.DataFrame(data_disc, columns=columns_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pós-processamento\n",
    "df['Cargo'] = df['Cargo'].str.replace('JUSTICA', 'JUSTIÇA')  # Corrige ortografia\n",
    "df['Cargo'] = df['Cargo'].str.replace('PEDIAIRA', 'PEDIATRA')  # Corrige ortografia\n",
    "df2['Cargo'] = df2['Cargo'].str.replace('JUSTICA', 'JUSTIÇA')  # Corrige ortografia\n",
    "df2['Cargo'] = df2['Cargo'].str.replace('PEDIAIRA', 'PEDIATRA')  # Corrige ortografia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados\n",
    "df.to_csv(\"prova_objetiva_compilado.csv\", index=False, encoding='utf-8-sig')\n",
    "df2.to_csv(\"prova_discursiva_compilado.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nTotal de registros extraídos: {len(df)} {len(df2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge (juntar) os DataFrames\n",
    "df_final = pd.merge(df, df2, on=\"Inscrição\", how=\"inner\")\n",
    "\n",
    "# Criar coluna com a soma das notas\n",
    "df_final[\"Nota Final\"] = df_final[\"Nota Objetiva\"] + df_final[\"Prova Discursiva\"]\n",
    "\n",
    "df_final = df_final.drop(columns=[\"Situação_x\", \"Cargo_x\", \"Local_x\", \"Nome_y\"])\n",
    "\n",
    "df_final = df_final.sort_values(by=\"Nota Final\", ascending=False)\n",
    "\n",
    "# Salvar em CSV (opcional)\n",
    "df_final.to_csv(\"dados_finais_tjro.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "print(f\"\\nTotal de registros extraídos: {len(df)} {len(df2)}  {len(df_final)}\")\n",
    "\n",
    "df_final.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
